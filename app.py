import streamlit as st
import os
import csv
import subprocess
import time
import warnings
from datetime import datetime
import joblib
import numpy as np
import pandas as pd
from io import BytesIO
from pydub import AudioSegment
import librosa
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
import tempfile
import logging

# Suppress warnings
warnings.filterwarnings('ignore')
logging.basicConfig(level=logging.INFO)

# === Configuration ===
AUDIO_CONFIG = {
    'SAMPLE_RATE': 22050,
    'N_MFCC': 13,
    'N_CHROMA': 12,
    'MAX_AUDIO_LENGTH': 30,
}

EMOTION_LABELS = ['happy', 'sad', 'angry', 'neutral']
SENTIMENT_LABELS = ['positive', 'negative', 'neutral']

# === Files ===
log_file = "results_log.csv"
train_script = "train_model.py"
last_run_file = "last_model_update.txt"

# === Streamlit Config ===
st.set_page_config(
    page_title="Speech Emotion & Sentiment Analyzer",
    page_icon="üéôÔ∏è",
    layout="wide"
)

# === Enhanced Feature Extraction ===
def extract_features_robust(audio_path):
    """Enhanced feature extraction with error handling and normalization"""
    try:
        # Load audio with proper error handling
        audio_data, sr = librosa.load(
            audio_path, 
            sr=AUDIO_CONFIG['SAMPLE_RATE'],
            duration=AUDIO_CONFIG['MAX_AUDIO_LENGTH']
        )
        
        if len(audio_data) == 0:
            st.error("Empty audio file")
            return None
            
        # Normalize audio
        audio_data = librosa.util.normalize(audio_data)
        
        features = []
        
        # 1. MFCC Features (most important for emotion)
        try:
            mfccs = librosa.feature.mfcc(
                y=audio_data, 
                sr=sr, 
                n_mfcc=AUDIO_CONFIG['N_MFCC']
            )
            # Statistical features from MFCC
            features.extend(np.mean(mfccs, axis=1))  # Mean
            features.extend(np.std(mfccs, axis=1))   # Standard deviation
            features.extend(np.max(mfccs, axis=1))   # Maximum
            features.extend(np.min(mfccs, axis=1))   # Minimum
        except Exception as e:
            st.warning(f"MFCC extraction failed: {e}")
            features.extend([0.0] * (AUDIO_CONFIG['N_MFCC'] * 4))
        
        # 2. Spectral Features
        try:
            # Spectral centroid (brightness)
            spectral_centroids = librosa.feature.spectral_centroid(y=audio_data, sr=sr)
            features.extend([
                np.mean(spectral_centroids),
                np.std(spectral_centroids),
                np.max(spectral_centroids),
                np.min(spectral_centroids)
            ])
            
            # Spectral rolloff
            spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)
            features.extend([
                np.mean(spectral_rolloff),
                np.std(spectral_rolloff)
            ])
            
            # Spectral bandwidth
            spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)
            features.extend([
                np.mean(spectral_bandwidth),
                np.std(spectral_bandwidth)
            ])
            
        except Exception as e:
            st.warning(f"Spectral features extraction failed: {e}")
            features.extend([0.0] * 8)
        
        # 3. Zero Crossing Rate (speech/music discrimination)
        try:
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features.extend([
                np.mean(zcr),
                np.std(zcr)
            ])
        except Exception as e:
            st.warning(f"ZCR extraction failed: {e}")
            features.extend([0.0, 0.0])
        
        # 4. Chroma Features (harmonic content)
        try:
            chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)
            features.extend(np.mean(chroma, axis=1))
            features.extend(np.std(chroma, axis=1))
        except Exception as e:
            st.warning(f"Chroma extraction failed: {e}")
            features.extend([0.0] * (AUDIO_CONFIG['N_CHROMA'] * 2))
        
        # 5. Tempo and Rhythm
        try:
            tempo, beats = librosa.beat.beat_track(y=audio_data, sr=sr)
            features.append(tempo)
            
            # Beat regularity
            if len(beats) > 1:
                beat_intervals = np.diff(beats)
                features.extend([
                    np.mean(beat_intervals),
                    np.std(beat_intervals)
                ])
            else:
                features.extend([0.0, 0.0])
                
        except Exception as e:
            st.warning(f"Tempo extraction failed: {e}")
            features.extend([120.0, 0.0, 0.0])  # Default tempo
        
        # 6. Energy and Power
        try:
            # RMS Energy
            rms = librosa.feature.rms(y=audio_data)
            features.extend([
                np.mean(rms),
                np.std(rms)
            ])
            
            # Total energy
            energy = np.sum(audio_data ** 2)
            features.append(energy)
            
        except Exception as e:
            st.warning(f"Energy extraction failed: {e}")
            features.extend([0.0, 0.0, 0.0])
        
        # Convert to numpy array and handle NaN/inf
        features = np.array(features, dtype=np.float32)
        features = np.nan_to_num(features, nan=0.0, posinf=1e6, neginf=-1e6)
        
        st.info(f"Extracted {len(features)} audio features")
        return features
        
    except Exception as e:
        st.error(f"Feature extraction failed: {str(e)}")
        return None

# === Enhanced Speech-to-Text ===
def enhanced_speech_to_text(audio_path, language="en-US"):
    """Enhanced speech-to-text with fallback options"""
    try:
        # Try Google Speech API (if available)
        from speech_to_text import speech_to_text
        transcription = speech_to_text(audio_path, language=language)
        
        if transcription and len(transcription.strip()) > 0:
            return transcription
        else:
            st.warning("Google Speech API returned empty transcription")
    except ImportError:
        st.warning("Google Speech API not available")
    except Exception as e:
        st.warning(f"Google Speech API failed: {e}")
    
    # Fallback: Simple transcription placeholder
    st.info("Using fallback transcription method")
    return "Audio transcription not available - analyzing audio features only"

# === Model Management ===
class ModelManager:
    def __init__(self):
        self.emotion_model = None
        self.sentiment_model = None
        self.vectorizer = None
        self.scaler = StandardScaler()
        self.load_models()
    
    def load_models(self):
        """Load models with proper error handling"""
        try:
            self.emotion_model = joblib.load("emotion_model.pkl")
            st.success("‚úÖ Emotion model loaded")
        except (FileNotFoundError, Exception) as e:
            st.warning("‚ö†Ô∏è Creating new emotion model")
            self.create_emotion_model()
        
        try:
            self.sentiment_model = joblib.load("sentiment_model.pkl")
            self.vectorizer = joblib.load("tfidf_vectorizer.pkl")
            st.success("‚úÖ Sentiment model loaded")
        except (FileNotFoundError, Exception) as e:
            st.warning("‚ö†Ô∏è Creating new sentiment model")
            self.create_sentiment_model()
    
    def create_emotion_model(self):
        """Create a basic emotion model"""
        try:
            # Generate synthetic training data for demonstration
            np.random.seed(42)
            n_samples = 1000
            n_features = 100  # Approximate number of features we extract
            
            X = np.random.rand(n_samples, n_features)
            y = np.random.choice(len(EMOTION_LABELS), n_samples)
            
            # Add some pattern to make it more realistic
            for i in range(len(EMOTION_LABELS)):
                mask = y == i
                X[mask] += np.random.normal(i * 0.5, 0.2, (np.sum(mask), n_features))
            
            # Fit scaler and transform data
            X_scaled = self.scaler.fit_transform(X)
            
            # Train model
            self.emotion_model = RandomForestClassifier(
                n_estimators=100,
                random_state=42,
                max_depth=10
            )
            self.emotion_model.fit(X_scaled, y)
            
            # Save models
            joblib.dump(self.emotion_model, "emotion_model.pkl")
            joblib.dump(self.scaler, "emotion_scaler.pkl")
            
            st.info("‚úÖ New emotion model created and saved")
            
        except Exception as e:
            st.error(f"Failed to create emotion model: {e}")
    
    def create_sentiment_model(self):
        """Create a basic sentiment model"""
        try:
            # Sample texts for training
            texts = [
                "I love this", "This is amazing", "Great job", "Wonderful experience",
                "I hate this", "This is terrible", "Awful experience", "Very disappointing",
                "It's okay", "Not bad", "Average performance", "Could be better"
            ]
            labels = [0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2]  # 0=positive, 1=negative, 2=neutral
            
            # Create vectorizer and model
            self.vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')
            X = self.vectorizer.fit_transform(texts)
            
            self.sentiment_model = LogisticRegression(random_state=42)
            self.sentiment_model.fit(X, labels)
            
            # Save models
            joblib.dump(self.sentiment_model, "sentiment_model.pkl")
            joblib.dump(self.vectorizer, "tfidf_vectorizer.pkl")
            
            st.info("‚úÖ New sentiment model created and saved")
            
        except Exception as e:
            st.error(f"Failed to create sentiment model: {e}")
    
    def predict_emotion(self, features):
        """Predict emotion with confidence"""
        if self.emotion_model is None or features is None:
            return "unknown", 0.0, None
        
        try:
            # Ensure features have the right shape
            if len(features.shape) == 1:
                features = features.reshape(1, -1)
            
            # Scale features
            features_scaled = self.scaler.transform(features)
            
            # Predict
            prediction = self.emotion_model.predict(features_scaled)[0]
            probabilities = self.emotion_model.predict_proba(features_scaled)[0]
            confidence = np.max(probabilities)
            
            emotion = EMOTION_LABELS[prediction]
            return emotion, confidence, probabilities
            
        except Exception as e:
            st.error(f"Emotion prediction failed: {e}")
            return "unknown", 0.0, None
    
    def predict_sentiment(self, text):
        """Predict sentiment with confidence"""
        if self.sentiment_model is None or self.vectorizer is None:
            return "unknown", 0.0, None
        
        try:
            # Vectorize text
            text_vector = self.vectorizer.transform([text])
            
            # Predict
            prediction = self.sentiment_model.predict(text_vector)[0]
            probabilities = self.sentiment_model.predict_proba(text_vector)[0]
            confidence = np.max(probabilities)
            
            sentiment = SENTIMENT_LABELS[prediction]
            return sentiment, confidence, probabilities
            
        except Exception as e:
            st.error(f"Sentiment prediction failed: {e}")
            return "unknown", 0.0, None

# === Retraining Functions ===
def should_retrain():
    """Check if models should be retrained"""
    if not os.path.exists(log_file):
        return False
    if not os.path.exists(last_run_file):
        return True
    try:
        with open(last_run_file, "r") as f:
            last_time = float(f.read().strip())
        return os.path.getmtime(log_file) > last_time
    except:
        return True

def retrain_models():
    """Retrain models with feedback data"""
    try:
        if os.path.exists(train_script):
            subprocess.run(["python", train_script])
        with open(last_run_file, "w") as f:
            f.write(str(time.time()))
        return True
    except Exception as e:
        st.error(f"Retraining failed: {e}")
        return False

# === Audio Processing ===
def convert_audio_to_wav(uploaded_file):
    """Convert uploaded audio to WAV format"""
    try:
        # Create temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.wav') as tmp_file:
            temp_path = tmp_file.name
        
        if uploaded_file.name.lower().endswith('.mp3'):
            # Convert MP3 to WAV
            audio = AudioSegment.from_file(BytesIO(uploaded_file.read()), format="mp3")
            audio.export(temp_path, format="wav")
        elif uploaded_file.name.lower().endswith('.wav'):
            # Save WAV directly
            with open(temp_path, "wb") as f:
                f.write(uploaded_file.read())
        else:
            # Try to convert other formats
            audio = AudioSegment.from_file(BytesIO(uploaded_file.read()))
            audio.export(temp_path, format="wav")
        
        return temp_path
        
    except Exception as e:
        st.error(f"Audio conversion failed: {e}")
        return None

# === Feedback Management ===
def save_result_to_csv(data, filename="results_log.csv"):
    """Save results with proper error handling"""
    try:
        file_exists = os.path.isfile(filename)
        with open(filename, mode="a", newline='', encoding="utf-8") as f:
            writer = csv.DictWriter(f, fieldnames=data.keys())
            if not file_exists:
                writer.writeheader()
            writer.writerow(data)
        return True
    except Exception as e:
        st.error(f"Failed to save feedback: {e}")
        return False

# === Main Application ===
def main():
    # === Title ===
    st.title("üéôÔ∏è Enhanced Speech Emotion & Sentiment Analyzer")
    st.markdown("Upload an audio file to analyze emotions and sentiments with improved accuracy")
    
    # === Initialize Model Manager ===
    if 'model_manager' not in st.session_state:
        st.session_state.model_manager = ModelManager()
    
    model_manager = st.session_state.model_manager
    
    # === Sidebar Controls ===
    st.sidebar.header("üîß Controls")
    
    # Manual retrain option
    if st.sidebar.button("üîÅ Force Retrain Models"):
        if retrain_models():
            st.sidebar.success("‚úÖ Models retrained manually.")
            # Reload models
            st.session_state.model_manager = ModelManager()
        else:
            st.sidebar.error("‚ùå Retraining failed.")
    
    # Auto-retrain check
    if should_retrain():
        st.info("üîÑ Training models from new feedback...")
        if retrain_models():
            st.success("‚úÖ Models updated automatically.")
            st.session_state.model_manager = ModelManager()
    
    # === File Upload ===
    uploaded_file = st.file_uploader(
        "üì§ Upload an audio file", 
        type=["mp3", "wav", "flac", "m4a"],
        help="Supported formats: MP3, WAV, FLAC, M4A"
    )
    
    if uploaded_file is not None:
        # Display file info
        st.success(f"File uploaded: {uploaded_file.name} ({uploaded_file.size} bytes)")
        
        # Convert to WAV
        temp_path = convert_audio_to_wav(uploaded_file)
        
        if temp_path is None:
            st.error("Failed to process audio file")
            return
        
        try:
            # === Language Selection ===
            st.subheader("üåç Transcription Language")
            language_map = {
                "English": "en-US",
                "Hindi": "hi-IN",
                "Telugu": "te-IN",
                "Tamil": "ta-IN",
                "Spanish": "es-ES",
                "German": "de-DE",
                "French": "fr-FR"
            }
            selected_language_label = st.selectbox("Language", list(language_map.keys()))
            selected_language = language_map[selected_language_label]
            
            # === Audio Analysis ===
            with st.spinner("üîç Analyzing audio..."):
                # Extract features
                features = extract_features_robust(temp_path)
                
                # Get transcription
                transcription = enhanced_speech_to_text(temp_path, language=selected_language)
                
                # Make predictions
                emotion, emotion_confidence, emotion_probs = model_manager.predict_emotion(features)
                sentiment, sentiment_confidence, sentiment_probs = model_manager.predict_sentiment(transcription)
            
            # === Display Results ===
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üé≠ Emotion Analysis")
                st.metric("Detected Emotion", emotion.title(), f"{emotion_confidence:.2%} confidence")
                
                if emotion_probs is not None:
                    emotion_df = pd.DataFrame({
                        'Emotion': EMOTION_LABELS,
                        'Probability': emotion_probs
                    }).sort_values('Probability', ascending=False)
                    st.bar_chart(emotion_df.set_index('Emotion'))
            
            with col2:
                st.subheader("üí≠ Sentiment Analysis")
                st.metric("Detected Sentiment", sentiment.title(), f"{sentiment_confidence:.2%} confidence")
                
                if sentiment_probs is not None:
                    sentiment_df = pd.DataFrame({
                        'Sentiment': SENTIMENT_LABELS,
                        'Probability': sentiment_probs
                    }).sort_values('Probability', ascending=False)
                    st.bar_chart(sentiment_df.set_index('Sentiment'))
            
            # === Transcription ===
            st.subheader("üéß Transcription")
            st.text_area("Transcribed Text", transcription, height=100)
            
            # === Feedback Section ===
            st.subheader("üìù Provide Feedback")
            st.markdown("Help improve our models by correcting any mistakes:")
            
            col3, col4 = st.columns(2)
            
            with col3:
                st.write("**Emotion Feedback**")
                emotion_feedback = st.radio(
                    "Was the emotion prediction correct?",
                    ["Yes", "No"],
                    key="emotion_feedback"
                )
                
                corrected_emotion = emotion
                if emotion_feedback == "No":
                    emotion_options = [e for e in EMOTION_LABELS if e != emotion]
                    corrected_emotion = st.selectbox(
                        "Select the correct emotion:",
                        emotion_options,
                        key="corrected_emotion"
                    )
            
            with col4:
                st.write("**Sentiment Feedback**")
                sentiment_feedback = st.radio(
                    "Was the sentiment prediction correct?",
                    ["Yes", "No"],
                    key="sentiment_feedback"
                )
                
                corrected_sentiment = sentiment
                if sentiment_feedback == "No":
                    sentiment_options = [s for s in SENTIMENT_LABELS if s != sentiment]
                    corrected_sentiment = st.selectbox(
                        "Select the correct sentiment:",
                        sentiment_options,
                        key="corrected_sentiment"
                    )
            
            # Submit feedback
            if st.button("üì® Submit Feedback", type="primary"):
                log_entry = {
                    "file_name": uploaded_file.name,
                    "transcription": transcription,
                    "predicted_emotion": emotion,
                    "emotion_confidence": round(emotion_confidence, 3),
                    "predicted_sentiment": sentiment,
                    "sentiment_confidence": round(sentiment_confidence, 3),
                    "user_feedback_emotion": emotion_feedback,
                    "corrected_emotion": corrected_emotion,
                    "user_feedback_sentiment": sentiment_feedback,
                    "corrected_sentiment": corrected_sentiment,
                    "timestamp": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                }
                
                if save_result_to_csv(log_entry):
                    st.success("‚úÖ Feedback submitted successfully! Thank you for helping improve our models.")
                    st.balloons()
                else:
                    st.error("‚ùå Failed to submit feedback. Please try again.")
        
        finally:
            # Clean up temporary file
            try:
                if os.path.exists(temp_path):
                    os.unlink(temp_path)
            except:
                pass
    
    # === Information ===
    with st.expander("‚ÑπÔ∏è About This Application"):
        st.markdown("""
        ### Enhanced Features:
        - **Robust Feature Extraction**: 100+ audio features including MFCC, spectral, chroma, and temporal features
        - **Improved Error Handling**: Graceful degradation when components fail
        - **Confidence Scores**: See how confident the model is in its predictions
        - **Visual Feedback**: Probability distributions for all predictions
        - **Multi-language Support**: Transcription in 7 languages
        - **Continuous Learning**: Models improve with your feedback
        
        ### Technical Improvements:
        - Enhanced audio preprocessing and normalization
        - Statistical feature extraction from multiple domains
        - Fallback mechanisms for failed components
        - Better model initialization and error recovery
        - Comprehensive logging and feedback system
        """)

if __name__ == "__main__":
    main()
